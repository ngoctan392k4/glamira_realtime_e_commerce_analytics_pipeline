FROM apache/spark:3.5.7-java17-python3
USER root
RUN apt update && apt install -y wget && apt install -y zip && apt install python-is-python3 && apt install -y python3.10-venv
RUN apt-get autoremove -y && apt-get clean && rm -rf /var/lib/apt/lists/*
RUN mkdir -p /data && chown -R spark:root /data
RUN mkdir -p /home/spark && chown -R spark:spark /home/spark && usermod -d /home/spark spark
RUN mkdir -p /home/spark/.ivy2 && chown -R spark:spark /home/spark/.ivy2
VOLUME /data
VOLUME /home/spark/.ivy2
COPY ./install-miniconda.sh /tmp/install-miniconda.sh
RUN chmod +x /tmp/install-miniconda.sh && chown spark:spark /tmp/install-miniconda.sh
COPY ./environment.yml /tmp/environment.yml
RUN chown spark:spark /tmp/environment.yml
USER spark
RUN bash /tmp/install-miniconda.sh && rm /tmp/install-miniconda.sh && rm /tmp/environment.yml
COPY environment.yml /tmp/environment.yml
RUN conda env create -f /tmp/environment.yml
ENV PYSPARK_PYTHON=/opt/conda/envs/pyspark_conda_env/bin/python
ENV PATH="/opt/spark/bin:/opt/spark/sbin:/home/spark/miniconda3/bin:$PATH"
